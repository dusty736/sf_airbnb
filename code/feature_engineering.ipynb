{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-explorer",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This notebook will engineer text features from the property reviews, and temporal features from calendar data.  The text features will include the top BOW words from the preprocessed text, and cluster labels after text embedding.  (May need extra computing power).  The temporal features will be aggregated features like average price of neighbourhood by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specialized-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in libraries\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "import yellowbrick\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import string\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import manifold\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#from deep_translator import GoogleTranslator\n",
    "import langid\n",
    "import holidays\n",
    "import datetime\n",
    "\n",
    "# Unlimited columns\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bearing-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "# Load calendar data\n",
    "calendar = pd.read_csv(\"../data/processed/calendar.csv\")\n",
    "\n",
    "# Load reviews data\n",
    "#review_map = pd.read_csv(\"../data/raw/reviews_ids.csv\")\n",
    "reviews = pd.read_csv(\"../data/processed/reviews.csv\")\n",
    "\n",
    "# Load listings data\n",
    "listings = pd.read_csv(\"../data/processed/listings.csv\")\n",
    "\n",
    "# Load neighborhoods\n",
    "neighborhoods = pd.read_csv(\"../data/processed/neighbourhoods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bored-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "# Description:  Turn into BOW, and keep top n words OHE\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    punctuation = string.punctuation\n",
    "    stop_words += list(punctuation)\n",
    "    stop_words.extend(['``','’', '`','br','\"',\"”\", \"''\", \"'s\", \"/b\"]) \n",
    "    text = text.replace(r'<br />',' ')\n",
    "    preprocessed = []    \n",
    "        \n",
    "    # Tokenization using nltk word tokenization\n",
    "    tokenized = word_tokenize(text)\n",
    "    for token in tokenized:\n",
    "        token = token.lower()\n",
    "        if token not in stop_words and len(token) > 1:\n",
    "            preprocessed.append(token)\n",
    "    return \" \".join(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "junior-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_clusters(\n",
    "    data,\n",
    "    cluster_labels,\n",
    "    raw_sents,\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Carry out dimensionality reduction using PCA and plot 2-dimensional clusters.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : numpy array\n",
    "        data as a numpy array\n",
    "    cluster_labels : list\n",
    "        cluster labels for each row in the dataset\n",
    "    raw_sents : list\n",
    "        the original raw sentences for labeling datapoints\n",
    "    show_labels : boolean\n",
    "        whether you want to show labels for points or not (default: False)\n",
    "    size : int\n",
    "        size of points in the scatterplot\n",
    "    title : str\n",
    "        title for the visualization plot\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    None. Shows the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_comp = pca.fit_transform(data)\n",
    "    pca_df = pd.DataFrame(data=principal_comp, columns=[\"pca1\", \"pca2\"])\n",
    "    pca_df[\"cluster\"] = cluster_labels\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(title)\n",
    "    ax = sns.scatterplot(\n",
    "        x=\"pca1\", y=\"pca2\", hue=\"cluster\", data=pca_df, palette=\"tab10\", s=size\n",
    "    )\n",
    "\n",
    "    x = pca_df[\"pca1\"].tolist()\n",
    "    y = pca_df[\"pca2\"].tolist()\n",
    "    if show_labels:\n",
    "        for i, txt in enumerate(raw_sents):\n",
    "            plt.annotate(\" \".join(txt.split()[:10]), (x[i], y[i]))\n",
    "        ax.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-ghost",
   "metadata": {},
   "source": [
    "## Review Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller dataset for testing code\n",
    "#random.seed(42)\n",
    "#test_ids = random.sample(list(set(reviews.listing_id)), 100)\n",
    "#test_data = reviews.query(\"listing_id in @test_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-accommodation",
   "metadata": {},
   "source": [
    "#### Remove empty string, remove extra characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tropical-valuable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>958</td>\n",
       "      <td>5977</td>\n",
       "      <td>2009-07-23</td>\n",
       "      <td>15695</td>\n",
       "      <td>Edmund C</td>\n",
       "      <td>experience without doubt five star experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>958</td>\n",
       "      <td>6660</td>\n",
       "      <td>2009-08-03</td>\n",
       "      <td>26145</td>\n",
       "      <td>Simon</td>\n",
       "      <td>returning san francisco rejuvenating thrill ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>958</td>\n",
       "      <td>11519</td>\n",
       "      <td>2009-09-27</td>\n",
       "      <td>25839</td>\n",
       "      <td>Denis</td>\n",
       "      <td>pleased accommodations friendly neighborhood a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>958</td>\n",
       "      <td>16282</td>\n",
       "      <td>2009-11-05</td>\n",
       "      <td>33750</td>\n",
       "      <td>Anna</td>\n",
       "      <td>highly recommend accomodation agree previous p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>958</td>\n",
       "      <td>26008</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>15416</td>\n",
       "      <td>Venetia</td>\n",
       "      <td>holly place great exactly needed perfect locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285270</th>\n",
       "      <td>285270</td>\n",
       "      <td>53258020</td>\n",
       "      <td>501567230864641900</td>\n",
       "      <td>2021-11-22</td>\n",
       "      <td>104345330</td>\n",
       "      <td>Paige</td>\n",
       "      <td>lovely stay craigs place room beautiful spacio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285271</th>\n",
       "      <td>285271</td>\n",
       "      <td>53258020</td>\n",
       "      <td>503009892202171652</td>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>203525522</td>\n",
       "      <td>Martha</td>\n",
       "      <td>craig exceptional host rooms common areas beau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285272</th>\n",
       "      <td>285272</td>\n",
       "      <td>53378110</td>\n",
       "      <td>500100974673293551</td>\n",
       "      <td>2021-11-20</td>\n",
       "      <td>3044891</td>\n",
       "      <td>David</td>\n",
       "      <td>'ve rented entire home upstairs downstairs wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285273</th>\n",
       "      <td>285273</td>\n",
       "      <td>53405558</td>\n",
       "      <td>507272106926274471</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>306384286</td>\n",
       "      <td>Juan</td>\n",
       "      <td>one best airbnb san francisco would come nice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285274</th>\n",
       "      <td>285274</td>\n",
       "      <td>53423350</td>\n",
       "      <td>500796999366277320</td>\n",
       "      <td>2021-11-21</td>\n",
       "      <td>3044891</td>\n",
       "      <td>David</td>\n",
       "      <td>'ve rented entire home upstairs downstairs wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285275 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  listing_id                  id        date  reviewer_id  \\\n",
       "0                0         958                5977  2009-07-23        15695   \n",
       "1                1         958                6660  2009-08-03        26145   \n",
       "2                2         958               11519  2009-09-27        25839   \n",
       "3                3         958               16282  2009-11-05        33750   \n",
       "4                4         958               26008  2010-02-13        15416   \n",
       "...            ...         ...                 ...         ...          ...   \n",
       "285270      285270    53258020  501567230864641900  2021-11-22    104345330   \n",
       "285271      285271    53258020  503009892202171652  2021-11-24    203525522   \n",
       "285272      285272    53378110  500100974673293551  2021-11-20      3044891   \n",
       "285273      285273    53405558  507272106926274471  2021-11-30    306384286   \n",
       "285274      285274    53423350  500796999366277320  2021-11-21      3044891   \n",
       "\n",
       "       reviewer_name                                           comments  \n",
       "0           Edmund C  experience without doubt five star experience ...  \n",
       "1              Simon  returning san francisco rejuvenating thrill ti...  \n",
       "2              Denis  pleased accommodations friendly neighborhood a...  \n",
       "3               Anna  highly recommend accomodation agree previous p...  \n",
       "4            Venetia  holly place great exactly needed perfect locat...  \n",
       "...              ...                                                ...  \n",
       "285270         Paige  lovely stay craigs place room beautiful spacio...  \n",
       "285271        Martha  craig exceptional host rooms common areas beau...  \n",
       "285272         David  've rented entire home upstairs downstairs wel...  \n",
       "285273          Juan  one best airbnb san francisco would come nice ...  \n",
       "285274         David  've rented entire home upstairs downstairs wel...  \n",
       "\n",
       "[285275 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn nan values into empty strings\n",
    "reviews.comments.replace(np.nan, \"\", inplace=True)\n",
    "\n",
    "# preprocess text\n",
    "reviews.assign(comments = reviews.comments.apply(preprocess_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-sudan",
   "metadata": {},
   "source": [
    "## Translate to English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-construction",
   "metadata": {},
   "source": [
    "The time taken to translate all non-english comments is roughly 12.2 hours, so non-english comments will be removed for now.  Translation to happen at a later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "original-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the language of each comment\n",
    "#test_data['language_tuple'] = test_data.comments.apply(langid.classify)\n",
    "#test_data[['lang', 'cert']] = pd.DataFrame(test_data['language_tuple'].tolist(), index=test_data.index)\n",
    "#test_data.drop(['language_tuple', 'cert'], axis=1, inplace=True)\n",
    "\n",
    "# Get non-English comments\n",
    "#non_english_comments = test_data.query(\"lang != 'en'\").comments.tolist()\n",
    "\n",
    "# tranlate the comments\n",
    "#non_english_comments = GoogleTranslator(source='auto', target='en').translate_batch(non_english_comments, )\n",
    "\n",
    "# Replace the non-english comments with tranlated versioins\n",
    "#test_data.loc[test_data.lang != 'en', 'comments'] = non_english_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-england",
   "metadata": {},
   "source": [
    "#### Remove non-english comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "south-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the language of each comment\n",
    "reviews['language_tuple'] = reviews.comments.apply(langid.classify)\n",
    "reviews[['lang', 'cert']] = pd.DataFrame(reviews['language_tuple'].tolist(), index=reviews.index)\n",
    "reviews.drop(['language_tuple', 'cert'], axis=1, inplace=True)\n",
    "reviews = reviews.query(\"lang == 'en'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-harassment",
   "metadata": {},
   "source": [
    "#### Add binary bow features for most common words in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "regional-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW\n",
    "# Create count vectorizer object.  Max features can be changed\n",
    "desc_n = 15\n",
    "vec = CountVectorizer(binary=True, max_features=desc_n)\n",
    "\n",
    "# Fit count vectorizer\n",
    "X_counts = vec.fit_transform(reviews.comments)\n",
    "\n",
    "# Create new features\n",
    "bow_df = pd.DataFrame(X_counts.toarray(), columns=[\"rev_\" + str(col) for col in list(vec.vocabulary_.keys())], index=reviews.index)\n",
    "\n",
    "# Add them onto the original dataframe\n",
    "reviews = reviews.join(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-device",
   "metadata": {},
   "source": [
    "#### Use NLTK's sentiment intensity analyzer to determine review sentiment.  Save score for pos, neg, neu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "existing-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "# https://www.nltk.org/howto/sentiment.html\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "neu_scores = []\n",
    "for rev in reviews.comments:\n",
    "    pos_scores.append(sia.polarity_scores(rev)['pos'])\n",
    "    neg_scores.append(sia.polarity_scores(rev)['neg'])\n",
    "    neu_scores.append(sia.polarity_scores(rev)['neu'])\n",
    "    \n",
    "reviews = reviews.assign(rev_pos_score = pos_scores, \n",
    "                 rev_neg_score = neg_scores,\n",
    "                 rev_neu_score = neu_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-newspaper",
   "metadata": {},
   "source": [
    "#### Cluster reviews, one hot encode cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "blessed-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "subtle-relative",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-adbec6c14eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcomment_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m comment_embeddings = pd.DataFrame(\n\u001b[1;32m      4\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         )\n\u001b[0;32m--> 843\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 )\n\u001b[1;32m    521\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    523\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     ):\n\u001b[0;32m--> 337\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "comment_data = reviews['comments'].tolist()\n",
    "embeddings = embedder.encode(comment_data)\n",
    "comment_embeddings = pd.DataFrame(\n",
    "    embeddings,\n",
    "    index=reviews.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(3, 10))\n",
    "\n",
    "visualizer.fit(comment_embeddings)  # Fit the data to the visualizer\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "km_labels_dict = {\n",
    "    k: KMeans(k).fit(comment_embeddings).predict(comment_embeddings) for k in np.arange(2, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, labels in km_labels_dict.items():\n",
    "    plot_pca_clusters(\n",
    "        comment_embeddings,\n",
    "        labels,\n",
    "        reviews['comments'],\n",
    "        size=10,\n",
    "        title=\"KMeans with sentence embeddings (k=%d)\" % (k),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "k = 4\n",
    "reviews['review_cluster'] = km_labels_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby('review_cluster').sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby(['review_cluster'])[['rev_pos_score', 'rev_neg_score', 'rev_neu_score']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-profession",
   "metadata": {},
   "source": [
    "**Summary:** Overall, the clusters don't seem helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "reviews['comment_length'] = reviews['comments'].str.split(\" \").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aggregations\n",
    "aggregation_dict = {'reviewer_id': 'count',\n",
    "                    'rev_clean': 'mean',\n",
    "                    'rev_place': 'mean',\n",
    "                    'rev_stay' : 'mean',\n",
    "                    'rev_would': 'mean',\n",
    "                    'rev_nice' : 'mean',\n",
    "                    'rev_great' : 'mean',\n",
    "                    'rev_easy' : 'mean',\n",
    "                    'rev_host' : 'mean',\n",
    "                    'rev_location' : 'mean',\n",
    "                    'rev_everything' : 'mean',\n",
    "                    'rev_comfortable' : 'mean',\n",
    "                    'rev_recommend' : 'mean',\n",
    "                    'rev_recommend' : 'mean',\n",
    "                    'rev_room' : 'mean',\n",
    "                    'rev_pos_score' : 'mean',\n",
    "                    'rev_neg_score' : 'mean',\n",
    "                    'rev_neu_score' : 'mean',\n",
    "                    'review_cluster' : pd.Series.mode,\n",
    "                    'comment_length' : 'mean',\n",
    "                    'rev_neu_score' : 'mean',\n",
    "                    'rev_neu_score' : 'mean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average positivity, neutral, and negative scores\n",
    "agg_reviews = reviews.groupby(\"listing_id\")\n",
    "agg_reviews = agg_reviews.agg(aggregation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_names = {\"reviewer_id\" : \"review_count\",\n",
    "             \"rev_clean\" : \"word_clean_use\",\n",
    "             \"rev_place\" : \"word_place_use\",\n",
    "             \"rev_stay\" : \"word_stay_use\",\n",
    "             \"rev_would\" : \"word_would_use\",\n",
    "             \"rev_nice\" : \"word_nice_use\",\n",
    "             \"rev_great\" : \"word_great_use\",\n",
    "             \"rev_easy\" : \"word_easy_use\",\n",
    "             \"rev_host\" : \"word_host_use\",\n",
    "             \"rev_location\" : \"word_location_use\",\n",
    "             \"rev_everything\" : \"word_everything_use\",\n",
    "             \"rev_comfortable\" : \"word_comfortable_use\",\n",
    "             \"rev_recommend\" : \"word_recommend_use\",\n",
    "             \"rev_room\" : \"word_room_use\",\n",
    "             \"rev_pos_score\" : \"positive_score_mean\",\n",
    "             \"rev_neg_score\" : \"negative_score_mean\",\n",
    "             \"rev_neu_score\" : \"neutral_score_mean\",\n",
    "             \"review_cluster\" : \"most_common_review_cluster\",\n",
    "             \"comment_length\" : \"average_comment_length\"}\n",
    "\n",
    "agg_reviews.rename(columns=agg_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_reviews = agg_reviews.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge relevant listing data\n",
    "agg_reviews = agg_reviews.merge(listings[['id', 'review_span']], left_on='listing_id', right_on='id').drop(columns=['id'])\n",
    "\n",
    "# Add reviews per review span\n",
    "agg_reviews = agg_reviews.assign(review_frequency = agg_reviews.review_count / agg_reviews.review_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_reviews = agg_reviews.drop(columns='review_span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-validity",
   "metadata": {},
   "source": [
    "## Calendar Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge neighbourhood data onto calendar data\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce date to datetime\n",
    "calendar['date'] = pd.to_datetime(calendar['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of week feature\n",
    "calendar = calendar.assign(day_of_week = calendar['date'].dt.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add week of year feature\n",
    "calendar = calendar.assign(week_of_year = calendar['date'].dt.isocalendar().week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month of year feature\n",
    "calendar = calendar.assign(month_of_year = calendar['date'].dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year feature\n",
    "calendar = calendar.assign(year = calendar['date'].dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add binary holiday feature\n",
    "# Get US holidays\n",
    "us_ca_holidays = holidays.country_holidays('US', subdiv='CA')\n",
    "\n",
    "# Format holidays\n",
    "us_ca_holidays = pd.DataFrame({\"holiday\":\n",
    "    [#datetime.date(2018, 1, 1),\n",
    "     #datetime.date(2018, 1, 15),\n",
    "     #datetime.date(2018, 2, 14),\n",
    "     #datetime.date(2018, 2, 19),\n",
    "     #datetime.date(2018, 3, 17),\n",
    "     #datetime.date(2018, 5, 5),\n",
    "     #datetime.date(2018, 5, 28),\n",
    "     #datetime.date(2018, 7, 4),\n",
    "     #datetime.date(2018, 8, 10),\n",
    "     #datetime.date(2018, 8, 11),\n",
    "     #datetime.date(2018, 8, 12),\n",
    "     #datetime.date(2018, 9, 3),\n",
    "     #datetime.date(2018, 10, 8),\n",
    "     #datetime.date(2018, 10, 31),\n",
    "     #datetime.date(2018, 11, 11),\n",
    "     #datetime.date(2018, 11, 12),\n",
    "     #datetime.date(2018, 11, 22),\n",
    "     #datetime.date(2018, 12, 25),\n",
    "     #datetime.date(2019, 1, 1),\n",
    "     #datetime.date(2019, 1, 15),\n",
    "     #datetime.date(2019, 2, 14),\n",
    "     #datetime.date(2019, 2, 19),\n",
    "     #datetime.date(2019, 3, 17),\n",
    "     #datetime.date(2019, 5, 5),\n",
    "     #datetime.date(2019, 5, 28),\n",
    "     #datetime.date(2019, 7, 4),\n",
    "     #datetime.date(2019, 8, 9),\n",
    "     #datetime.date(2019, 8, 10),\n",
    "     #datetime.date(2019, 8, 11),\n",
    "     #datetime.date(2019, 9, 3),\n",
    "     #datetime.date(2019, 10, 8),\n",
    "     #datetime.date(2019, 10, 31),\n",
    "     #datetime.date(2019, 11, 11),\n",
    "     #datetime.date(2019, 11, 12),\n",
    "     #datetime.date(2019, 11, 22),\n",
    "     #datetime.date(2019, 12, 25),\n",
    "     ##datetime.date(2020, 1, 1),\n",
    "     #datetime.date(2020, 1, 15),\n",
    "     #datetime.date(2020, 2, 14),\n",
    "     #datetime.date(2020, 2, 19),\n",
    "     #datetime.date(2020, 3, 17),\n",
    "     #datetime.date(2020, 5, 5),\n",
    "     #datetime.date(2020, 5, 28),\n",
    "     #datetime.date(2020, 7, 4),\n",
    "     #datetime.date(2020, 9, 3),\n",
    "     #datetime.date(2020, 10, 8),\n",
    "     datetime.date(2020, 10, 31),\n",
    "     datetime.date(2020, 11, 11),\n",
    "     datetime.date(2020, 11, 12),\n",
    "     datetime.date(2020, 11, 22),\n",
    "     datetime.date(2020, 12, 25),\n",
    "     datetime.date(2021, 1, 1),\n",
    "     datetime.date(2021, 1, 15),\n",
    "     datetime.date(2021, 2, 14),\n",
    "     datetime.date(2021, 2, 19),\n",
    "     datetime.date(2021, 3, 17),\n",
    "     datetime.date(2021, 5, 5),\n",
    "     datetime.date(2021, 5, 28),\n",
    "     datetime.date(2021, 7, 4),\n",
    "     datetime.date(2021, 9, 3),\n",
    "     datetime.date(2021, 10, 8),\n",
    "     datetime.date(2021, 10, 29),\n",
    "     datetime.date(2021, 10, 30),\n",
    "     datetime.date(2021, 10, 31),\n",
    "     datetime.date(2021, 11, 11),\n",
    "     datetime.date(2021, 11, 12),\n",
    "     datetime.date(2021, 11, 22),\n",
    "     datetime.date(2021, 12, 25),\n",
    "     datetime.date(2022, 1, 1),\n",
    "     datetime.date(2022, 1, 15),\n",
    "     datetime.date(2022, 2, 14),\n",
    "     datetime.date(2022, 2, 19),\n",
    "     datetime.date(2022, 3, 17),\n",
    "     datetime.date(2022, 5, 5),\n",
    "     datetime.date(2022, 5, 28),\n",
    "     datetime.date(2022, 7, 4),\n",
    "     datetime.date(2022, 8, 5),\n",
    "     datetime.date(2022, 8, 6),\n",
    "     datetime.date(2022, 8, 7),\n",
    "     datetime.date(2022, 9, 3),\n",
    "     datetime.date(2022, 10, 8),\n",
    "     datetime.date(2022, 10, 31),\n",
    "     datetime.date(2022, 11, 11),\n",
    "     datetime.date(2022, 11, 12),\n",
    "     datetime.date(2022, 11, 22),\n",
    "     datetime.date(2022, 12, 25)]}\n",
    ")\n",
    "\n",
    "us_ca_holidays['holiday'] = pd.to_datetime(us_ca_holidays['holiday'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def nearest_holiday(date_series, holidays):\n",
    "#    min_holiday_dist = []\n",
    "#    for i, date in enumerate(date_series):\n",
    "#        min_holiday_dist.append(min(abs(holidays - date)).days)\n",
    "#    return(min_holiday_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = [date.date() for date in us_ca_holidays['holiday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = calendar.assign(holiday = [True if date.date() in holidays else False for date in calendar.date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_duration_agg = calendar.groupby('listing_id')[['available', 'minimum_nights', 'maximum_nights']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of week aggregations\n",
    "dow_agg = calendar.groupby(['listing_id', 'day_of_week'])[['price']].mean()\n",
    "dow_agg = dow_agg.reset_index()\n",
    "dow_pivot = dow_agg.pivot(index='listing_id', columns='day_of_week', values='price').reset_index()\n",
    "dow_columns = ['listing_id'] + ['day_of_week_' + str(i) for i in dow_pivot.columns[1:]]\n",
    "dow_pivot.columns = dow_columns\n",
    "\n",
    "# week of year aggregations\n",
    "woy_agg = calendar.groupby(['listing_id', 'week_of_year'])[['price']].mean()\n",
    "woy_agg = woy_agg.reset_index()\n",
    "woy_pivot = woy_agg.pivot(index='listing_id', columns='week_of_year', values='price').reset_index()\n",
    "woy_columns = ['listing_id'] + ['week_of_year_' + str(i) for i in woy_pivot.columns[1:]]\n",
    "woy_pivot.columns = woy_columns\n",
    "\n",
    "# day of week aggregations\n",
    "moy_agg = calendar.groupby(['listing_id', 'month_of_year'])[['price']].mean()\n",
    "moy_agg = moy_agg.reset_index()\n",
    "moy_pivot = moy_agg.pivot(index='listing_id', columns='month_of_year', values='price').reset_index()\n",
    "moy_columns = ['listing_id'] + ['month_of_year_' + str(i) for i in moy_pivot.columns[1:]]\n",
    "moy_pivot.columns = moy_columns\n",
    "\n",
    "# day of week aggregations\n",
    "year_agg = calendar.groupby(['listing_id', 'year'])[['price']].mean()\n",
    "year_agg = year_agg.reset_index()\n",
    "year_pivot = year_agg.pivot(index='listing_id', columns='year', values='price').reset_index()\n",
    "year_columns = ['listing_id'] + ['year_' + str(i) for i in year_pivot.columns[1:]]\n",
    "year_pivot.columns = year_columns\n",
    "\n",
    "# holiday aggregations\n",
    "holiday_agg = calendar.groupby(['listing_id', 'holiday'])[['price']].mean()\n",
    "holiday_agg = holiday_agg.reset_index()\n",
    "holiday_pivot = holiday_agg.pivot(index='listing_id', columns='holiday', values='price').reset_index()\n",
    "holiday_columns = ['listing_id'] + ['holiday_' + str(i) for i in holiday_pivot.columns[1:]]\n",
    "holiday_pivot.columns = holiday_columns\n",
    "\n",
    "# Merge together\n",
    "calendar_aggregates = dow_pivot.merge(woy_pivot, on='listing_id').merge(moy_pivot, on='listing_id').merge(year_pivot, on='listing_id').merge(holiday_pivot, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_aggregates = calendar_aggregates.merge(calendar_duration_agg, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_aggregates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-possession",
   "metadata": {},
   "source": [
    "## Listings Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_columns = ['id',\n",
    "                     'host_id',\n",
    "                     'host_response_time',\n",
    "                     'host_response_rate',\n",
    "                     'host_acceptance_rate',\n",
    "                     'host_is_superhost',\n",
    "                     'host_neighbourhood',\n",
    "                     'host_listings_count',\n",
    "                     'host_total_listings_count',\n",
    "                     'host_has_profile_pic',\n",
    "                     'host_identity_verified',\n",
    "                     'neighbourhood_cleansed',\n",
    "                     'neighbourhood_group_cleansed',\n",
    "                     'latitude',\n",
    "                     'longitude',\n",
    "                     'property_type',\n",
    "                     'room_type',\n",
    "                     'accommodates',\n",
    "                     'bedrooms',\n",
    "                     'beds',\n",
    "                     'price',\n",
    "                     'minimum_nights',\n",
    "                     'maximum_nights',\n",
    "                     'minimum_minimum_nights',\n",
    "                     'maximum_minimum_nights',\n",
    "                     'minimum_maximum_nights',\n",
    "                     'maximum_maximum_nights',\n",
    "                     'minimum_nights_avg_ntm',\n",
    "                     'maximum_nights_avg_ntm',\n",
    "                     'has_availability',\n",
    "                     'availability_30',\n",
    "                     'availability_60',\n",
    "                     'availability_90',\n",
    "                     'availability_365',\n",
    "                     'number_of_reviews',\n",
    "                     'number_of_reviews_ltm',\n",
    "                     'number_of_reviews_l30d',\n",
    "                     'review_scores_rating',\n",
    "                     'review_scores_accuracy',\n",
    "                     'review_scores_cleanliness',\n",
    "                     'review_scores_checkin',\n",
    "                     'review_scores_communication',\n",
    "                     'review_scores_location',\n",
    "                     'review_scores_value',\n",
    "                     'instant_bookable',\n",
    "                     'calculated_host_listings_count',\n",
    "                     'calculated_host_listings_count_entire_homes',\n",
    "                     'calculated_host_listings_count_private_rooms',\n",
    "                     'calculated_host_listings_count_shared_rooms',\n",
    "                     'reviews_per_month',\n",
    "                     'desc_apartment',\n",
    "                     'desc_located',\n",
    "                     'desc_space',\n",
    "                     'desc_home',\n",
    "                     'desc_bed',\n",
    "                     'desc_room',\n",
    "                     'desc_kitchen',\n",
    "                     'desc_access',\n",
    "                     'desc_one',\n",
    "                     'desc_private',\n",
    "                     'desc_san',\n",
    "                     'desc_francisco',\n",
    "                     'desc_bathroom',\n",
    "                     'desc_bedroom',\n",
    "                     'desc_living',\n",
    "                     'host_in_sf',\n",
    "                     'host_verifications_email',\n",
    "                     'host_verifications_facebook',\n",
    "                     'host_verifications_google',\n",
    "                     'host_verifications_government_id',\n",
    "                     'host_verifications_identity_manual',\n",
    "                     'host_verifications_jumio',\n",
    "                     'host_verifications_kba',\n",
    "                     'host_verifications_manual_offline',\n",
    "                     'host_verifications_manual_online',\n",
    "                     'host_verifications_offline_government_id',\n",
    "                     'host_verifications_phone',\n",
    "                     'host_verifications_reviews',\n",
    "                     'host_verifications_selfie',\n",
    "                     'host_verifications_sent_id',\n",
    "                     'host_verifications_work_email',\n",
    "                     'host_verifications_zhima_selfie',\n",
    "                     'bathroom_private',\n",
    "                     'bathroom_shared',\n",
    "                     'bathroom_half',\n",
    "                     'bathroom_count',\n",
    "                     'amenities_Wifi',\n",
    "                     'amenities_Smoke alarm',\n",
    "                     'amenities_Essentials',\n",
    "                     'amenities_Heating',\n",
    "                     'amenities_Hangers',\n",
    "                     'amenities_Carbon monoxide alarm',\n",
    "                     'amenities_Hair dryer',\n",
    "                     'amenities_Iron',\n",
    "                     'amenities_Long term stays allowed',\n",
    "                     'amenities_Kitchen',\n",
    "                     'amenities_Shampoo',\n",
    "                     'amenities_Dedicated workspace',\n",
    "                     'amenities_Hot water',\n",
    "                     'amenities_Washer',\n",
    "                     'amenities_Fire extinguisher',\n",
    "                     'amenities_Dryer',\n",
    "                     'amenities_Coffee maker',\n",
    "                     'amenities_Refrigerator',\n",
    "                     'amenities_Microwave',\n",
    "                     'amenities_Dishes and silverware',\n",
    "                     'amenities_Bed linens',\n",
    "                     'amenities_TV',\n",
    "                     'amenities_Cooking basics',\n",
    "                     'amenities_First aid kit',\n",
    "                     'amenities_Private entrance',\n",
    "                     'amenities_Free street parking',\n",
    "                     'amenities_Oven',\n",
    "                     'amenities_Stove',\n",
    "                     'amenities_Extra pillows and blankets',\n",
    "                     'amenities_Dishwasher',\n",
    "                     'review_span',\n",
    "                     't_since_last_review',\n",
    "                     't_as_host',\n",
    "                     'has_license']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the desired features\n",
    "listings_modeling = listings[modeling_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "listings_modeling.rename(columns={'id' : 'listing_id', 'price' : 'listing_price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_modeling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-brother",
   "metadata": {},
   "source": [
    "## Create the Modeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = calendar[['listing_id', 'date', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.merge(agg_reviews, on='listing_id').merge(calendar_aggregates, on='listing_id').merge(listings_modeling, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-brazilian",
   "metadata": {},
   "source": [
    "## Split into Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create smaller dataset for testing code\n",
    "train_fraction = 0.8\n",
    "number_of_listings = len(set(base.listing_id))\n",
    "\n",
    "train_size = round(train_fraction * number_of_listings)\n",
    "train_ids = random.sample(list(set(base.listing_id)), train_size)\n",
    "test_ids = [listing for listing in base.listing_id if listing not in train_ids]\n",
    "\n",
    "train_data = base.query(\"listing_id in @train_ids\")\n",
    "test_data = base.query(\"listing_id in @test_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train_data.listing_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(test_data.listing_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output path\n",
    "out_path = \"../data/ready_for_modeling/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make processed folder\n",
    "#if ~os.direxists(\"../data/ready_for_modeling\"):\n",
    "#    os.mkdir(\"../data/ready_for_modeling\")\n",
    "try:\n",
    "    os.mkdir(\"../data/ready_for_modeling\")\n",
    "except:\n",
    "    print(\"Processed directory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disc\n",
    "train_path = out_path + \"training_data.csv\"\n",
    "train_data.to_csv(train_path)\n",
    "\n",
    "test_path = out_path + \"testing_data.csv\"\n",
    "test_data.to_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-genetics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
