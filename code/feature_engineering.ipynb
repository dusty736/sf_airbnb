{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "improved-relative",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This notebook will engineer text features from the property reviews, and temporal features from calendar data.  The text features will include the top BOW words from the preprocessed text, and cluster labels after text embedding.  (May need extra computing power).  The temporal features will be aggregated features like average price of neighbourhood by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interesting-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in libraries\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "import yellowbrick\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import string\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import manifold\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#from deep_translator import GoogleTranslator\n",
    "import langid\n",
    "import holidays\n",
    "import datetime\n",
    "\n",
    "# Unlimited columns\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "narrative-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "# Load calendar data\n",
    "calendar = pd.read_csv(\"../data/processed/calendar.csv\")\n",
    "\n",
    "# Load reviews data\n",
    "#review_map = pd.read_csv(\"../data/raw/reviews_ids.csv\")\n",
    "reviews = pd.read_csv(\"../data/processed/reviews.csv\")\n",
    "\n",
    "# Load listings data\n",
    "listings = pd.read_csv(\"../data/processed/listings.csv\")\n",
    "\n",
    "# Load neighborhoods\n",
    "neighborhoods = pd.read_csv(\"../data/processed/neighbourhoods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "# Description:  Turn into BOW, and keep top n words OHE\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    punctuation = string.punctuation\n",
    "    stop_words += list(punctuation)\n",
    "    stop_words.extend(['``','’', '`','br','\"',\"”\", \"''\", \"'s\", \"/b\"]) \n",
    "    text = text.replace(r'<br />',' ')\n",
    "    preprocessed = []    \n",
    "        \n",
    "    # Tokenization using nltk word tokenization\n",
    "    tokenized = word_tokenize(text)\n",
    "    for token in tokenized:\n",
    "        token = token.lower()\n",
    "        if token not in stop_words and len(token) > 1:\n",
    "            preprocessed.append(token)\n",
    "    return \" \".join(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_clusters(\n",
    "    data,\n",
    "    cluster_labels,\n",
    "    raw_sents,\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Carry out dimensionality reduction using PCA and plot 2-dimensional clusters.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : numpy array\n",
    "        data as a numpy array\n",
    "    cluster_labels : list\n",
    "        cluster labels for each row in the dataset\n",
    "    raw_sents : list\n",
    "        the original raw sentences for labeling datapoints\n",
    "    show_labels : boolean\n",
    "        whether you want to show labels for points or not (default: False)\n",
    "    size : int\n",
    "        size of points in the scatterplot\n",
    "    title : str\n",
    "        title for the visualization plot\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    None. Shows the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_comp = pca.fit_transform(data)\n",
    "    pca_df = pd.DataFrame(data=principal_comp, columns=[\"pca1\", \"pca2\"])\n",
    "    pca_df[\"cluster\"] = cluster_labels\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(title)\n",
    "    ax = sns.scatterplot(\n",
    "        x=\"pca1\", y=\"pca2\", hue=\"cluster\", data=pca_df, palette=\"tab10\", s=size\n",
    "    )\n",
    "\n",
    "    x = pca_df[\"pca1\"].tolist()\n",
    "    y = pca_df[\"pca2\"].tolist()\n",
    "    if show_labels:\n",
    "        for i, txt in enumerate(raw_sents):\n",
    "            plt.annotate(\" \".join(txt.split()[:10]), (x[i], y[i]))\n",
    "        ax.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-activation",
   "metadata": {},
   "source": [
    "## Review Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller dataset for testing code\n",
    "#random.seed(42)\n",
    "#test_ids = random.sample(list(set(reviews.listing_id)), 100)\n",
    "#test_data = reviews.query(\"listing_id in @test_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-growing",
   "metadata": {},
   "source": [
    "#### Remove empty string, remove extra characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn nan values into empty strings\n",
    "reviews.comments.replace(np.nan, \"\", inplace=True)\n",
    "\n",
    "# preprocess text\n",
    "reviews.assign(comments = reviews.comments.apply(preprocess_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-warehouse",
   "metadata": {},
   "source": [
    "## Translate to English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-chapel",
   "metadata": {},
   "source": [
    "The time taken to translate all non-english comments is roughly 12.2 hours, so non-english comments will be removed for now.  Translation to happen at a later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the language of each comment\n",
    "#test_data['language_tuple'] = test_data.comments.apply(langid.classify)\n",
    "#test_data[['lang', 'cert']] = pd.DataFrame(test_data['language_tuple'].tolist(), index=test_data.index)\n",
    "#test_data.drop(['language_tuple', 'cert'], axis=1, inplace=True)\n",
    "\n",
    "# Get non-English comments\n",
    "#non_english_comments = test_data.query(\"lang != 'en'\").comments.tolist()\n",
    "\n",
    "# tranlate the comments\n",
    "#non_english_comments = GoogleTranslator(source='auto', target='en').translate_batch(non_english_comments, )\n",
    "\n",
    "# Replace the non-english comments with tranlated versioins\n",
    "#test_data.loc[test_data.lang != 'en', 'comments'] = non_english_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-hebrew",
   "metadata": {},
   "source": [
    "#### Remove non-english comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the language of each comment\n",
    "reviews['language_tuple'] = reviews.comments.apply(langid.classify)\n",
    "reviews[['lang', 'cert']] = pd.DataFrame(reviews['language_tuple'].tolist(), index=reviews.index)\n",
    "reviews.drop(['language_tuple', 'cert'], axis=1, inplace=True)\n",
    "reviews = reviews.query(\"lang == 'en'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-lobby",
   "metadata": {},
   "source": [
    "#### Add binary bow features for most common words in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW\n",
    "# Create count vectorizer object.  Max features can be changed\n",
    "desc_n = 15\n",
    "vec = CountVectorizer(binary=True, max_features=desc_n)\n",
    "\n",
    "# Fit count vectorizer\n",
    "X_counts = vec.fit_transform(reviews.comments)\n",
    "\n",
    "# Create new features\n",
    "bow_df = pd.DataFrame(X_counts.toarray(), columns=[\"rev_\" + str(col) for col in list(vec.vocabulary_.keys())], index=reviews.index)\n",
    "\n",
    "# Add them onto the original dataframe\n",
    "reviews = reviews.join(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-constitutional",
   "metadata": {},
   "source": [
    "#### Use NLTK's sentiment intensity analyzer to determine review sentiment.  Save score for pos, neg, neu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "# https://www.nltk.org/howto/sentiment.html\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "neu_scores = []\n",
    "for rev in reviews.comments:\n",
    "    pos_scores.append(sia.polarity_scores(rev)['pos'])\n",
    "    neg_scores.append(sia.polarity_scores(rev)['neg'])\n",
    "    neu_scores.append(sia.polarity_scores(rev)['neu'])\n",
    "    \n",
    "reviews = reviews.assign(rev_pos_score = pos_scores, \n",
    "                 rev_neg_score = neg_scores,\n",
    "                 rev_neu_score = neu_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-style",
   "metadata": {},
   "source": [
    "#### Cluster reviews, one hot encode cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_data = reviews['comments'].tolist()\n",
    "embeddings = embedder.encode(comment_data)\n",
    "comment_embeddings = pd.DataFrame(\n",
    "    embeddings,\n",
    "    index=reviews.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(3, 10))\n",
    "\n",
    "visualizer.fit(comment_embeddings)  # Fit the data to the visualizer\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "km_labels_dict = {\n",
    "    k: KMeans(k).fit(comment_embeddings).predict(comment_embeddings) for k in np.arange(2, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, labels in km_labels_dict.items():\n",
    "    plot_pca_clusters(\n",
    "        comment_embeddings,\n",
    "        labels,\n",
    "        reviews['comments'],\n",
    "        size=10,\n",
    "        title=\"KMeans with sentence embeddings (k=%d)\" % (k),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "k = 4\n",
    "reviews['review_cluster'] = km_labels_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby('review_cluster').sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby(['review_cluster'])[['rev_pos_score', 'rev_neg_score', 'rev_neu_score']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-puzzle",
   "metadata": {},
   "source": [
    "**Summary:** Overall, the clusters don't seem helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "reviews['comment_length'] = reviews['comments'].str.split(\" \").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aggregations\n",
    "aggregation_dict = {'reviewer_id': 'count',\n",
    "                    'rev_clean': 'mean',\n",
    "                    'rev_place': 'mean',\n",
    "                    'rev_stay' : 'mean',\n",
    "                    'rev_would': 'mean',\n",
    "                    'rev_nice' : 'mean',\n",
    "                    'rev_great' : 'mean',\n",
    "                    'rev_easy' : 'mean',\n",
    "                    'rev_host' : 'mean',\n",
    "                    'rev_location' : 'mean',\n",
    "                    'rev_everything' : 'mean',\n",
    "                    'rev_comfortable' : 'mean',\n",
    "                    'rev_recommend' : 'mean',\n",
    "                    'rev_recommend' : 'mean',\n",
    "                    'rev_room' : 'mean',\n",
    "                    'rev_pos_score' : 'mean',\n",
    "                    'rev_neg_score' : 'mean',\n",
    "                    'rev_neu_score' : 'mean',\n",
    "                    'review_cluster' : pd.Series.mode,\n",
    "                    'comment_length' : 'mean',\n",
    "                    'rev_neu_score' : 'mean',\n",
    "                    'rev_neu_score' : 'mean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average positivity, neutral, and negative scores\n",
    "agg_reviews = reviews.groupby(\"listing_id\")\n",
    "agg_reviews = agg_reviews.agg(aggregation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_names = {\"reviewer_id\" : \"review_count\",\n",
    "             \"rev_clean\" : \"word_clean_use\",\n",
    "             \"rev_place\" : \"word_place_use\",\n",
    "             \"rev_stay\" : \"word_stay_use\",\n",
    "             \"rev_would\" : \"word_would_use\",\n",
    "             \"rev_nice\" : \"word_nice_use\",\n",
    "             \"rev_great\" : \"word_great_use\",\n",
    "             \"rev_easy\" : \"word_easy_use\",\n",
    "             \"rev_host\" : \"word_host_use\",\n",
    "             \"rev_location\" : \"word_location_use\",\n",
    "             \"rev_everything\" : \"word_everything_use\",\n",
    "             \"rev_comfortable\" : \"word_comfortable_use\",\n",
    "             \"rev_recommend\" : \"word_recommend_use\",\n",
    "             \"rev_room\" : \"word_room_use\",\n",
    "             \"rev_pos_score\" : \"positive_score_mean\",\n",
    "             \"rev_neg_score\" : \"negative_score_mean\",\n",
    "             \"rev_neu_score\" : \"neutral_score_mean\",\n",
    "             \"review_cluster\" : \"most_common_review_cluster\",\n",
    "             \"comment_length\" : \"average_comment_length\"}\n",
    "\n",
    "agg_reviews.rename(columns=agg_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_reviews = agg_reviews.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge relevant listing data\n",
    "agg_reviews = agg_reviews.merge(listings[['id', 'review_span']], left_on='listing_id', right_on='id').drop(columns=['id'])\n",
    "\n",
    "# Add reviews per review span\n",
    "agg_reviews = agg_reviews.assign(review_frequency = agg_reviews.review_count / agg_reviews.review_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_reviews = agg_reviews.drop(columns='review_span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-nomination",
   "metadata": {},
   "source": [
    "## Calendar Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge neighbourhood data onto calendar data\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce date to datetime\n",
    "calendar['date'] = pd.to_datetime(calendar['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of week feature\n",
    "calendar = calendar.assign(day_of_week = calendar['date'].dt.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add week of year feature\n",
    "calendar = calendar.assign(week_of_year = calendar['date'].dt.isocalendar().week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month of year feature\n",
    "calendar = calendar.assign(month_of_year = calendar['date'].dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year feature\n",
    "calendar = calendar.assign(year = calendar['date'].dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add binary holiday feature\n",
    "# Get US holidays\n",
    "us_ca_holidays = holidays.country_holidays('US', subdiv='CA')\n",
    "\n",
    "# Format holidays\n",
    "us_ca_holidays = pd.DataFrame({\"holiday\":\n",
    "    [#datetime.date(2018, 1, 1),\n",
    "     #datetime.date(2018, 1, 15),\n",
    "     #datetime.date(2018, 2, 14),\n",
    "     #datetime.date(2018, 2, 19),\n",
    "     #datetime.date(2018, 3, 17),\n",
    "     #datetime.date(2018, 5, 5),\n",
    "     #datetime.date(2018, 5, 28),\n",
    "     #datetime.date(2018, 7, 4),\n",
    "     #datetime.date(2018, 8, 10),\n",
    "     #datetime.date(2018, 8, 11),\n",
    "     #datetime.date(2018, 8, 12),\n",
    "     #datetime.date(2018, 9, 3),\n",
    "     #datetime.date(2018, 10, 8),\n",
    "     #datetime.date(2018, 10, 31),\n",
    "     #datetime.date(2018, 11, 11),\n",
    "     #datetime.date(2018, 11, 12),\n",
    "     #datetime.date(2018, 11, 22),\n",
    "     #datetime.date(2018, 12, 25),\n",
    "     #datetime.date(2019, 1, 1),\n",
    "     #datetime.date(2019, 1, 15),\n",
    "     #datetime.date(2019, 2, 14),\n",
    "     #datetime.date(2019, 2, 19),\n",
    "     #datetime.date(2019, 3, 17),\n",
    "     #datetime.date(2019, 5, 5),\n",
    "     #datetime.date(2019, 5, 28),\n",
    "     #datetime.date(2019, 7, 4),\n",
    "     #datetime.date(2019, 8, 9),\n",
    "     #datetime.date(2019, 8, 10),\n",
    "     #datetime.date(2019, 8, 11),\n",
    "     #datetime.date(2019, 9, 3),\n",
    "     #datetime.date(2019, 10, 8),\n",
    "     #datetime.date(2019, 10, 31),\n",
    "     #datetime.date(2019, 11, 11),\n",
    "     #datetime.date(2019, 11, 12),\n",
    "     #datetime.date(2019, 11, 22),\n",
    "     #datetime.date(2019, 12, 25),\n",
    "     ##datetime.date(2020, 1, 1),\n",
    "     #datetime.date(2020, 1, 15),\n",
    "     #datetime.date(2020, 2, 14),\n",
    "     #datetime.date(2020, 2, 19),\n",
    "     #datetime.date(2020, 3, 17),\n",
    "     #datetime.date(2020, 5, 5),\n",
    "     #datetime.date(2020, 5, 28),\n",
    "     #datetime.date(2020, 7, 4),\n",
    "     #datetime.date(2020, 9, 3),\n",
    "     #datetime.date(2020, 10, 8),\n",
    "     datetime.date(2020, 10, 31),\n",
    "     datetime.date(2020, 11, 11),\n",
    "     datetime.date(2020, 11, 12),\n",
    "     datetime.date(2020, 11, 22),\n",
    "     datetime.date(2020, 12, 25),\n",
    "     datetime.date(2021, 1, 1),\n",
    "     datetime.date(2021, 1, 15),\n",
    "     datetime.date(2021, 2, 14),\n",
    "     datetime.date(2021, 2, 19),\n",
    "     datetime.date(2021, 3, 17),\n",
    "     datetime.date(2021, 5, 5),\n",
    "     datetime.date(2021, 5, 28),\n",
    "     datetime.date(2021, 7, 4),\n",
    "     datetime.date(2021, 9, 3),\n",
    "     datetime.date(2021, 10, 8),\n",
    "     datetime.date(2021, 10, 29),\n",
    "     datetime.date(2021, 10, 30),\n",
    "     datetime.date(2021, 10, 31),\n",
    "     datetime.date(2021, 11, 11),\n",
    "     datetime.date(2021, 11, 12),\n",
    "     datetime.date(2021, 11, 22),\n",
    "     datetime.date(2021, 12, 25),\n",
    "     datetime.date(2022, 1, 1),\n",
    "     datetime.date(2022, 1, 15),\n",
    "     datetime.date(2022, 2, 14),\n",
    "     datetime.date(2022, 2, 19),\n",
    "     datetime.date(2022, 3, 17),\n",
    "     datetime.date(2022, 5, 5),\n",
    "     datetime.date(2022, 5, 28),\n",
    "     datetime.date(2022, 7, 4),\n",
    "     datetime.date(2022, 8, 5),\n",
    "     datetime.date(2022, 8, 6),\n",
    "     datetime.date(2022, 8, 7),\n",
    "     datetime.date(2022, 9, 3),\n",
    "     datetime.date(2022, 10, 8),\n",
    "     datetime.date(2022, 10, 31),\n",
    "     datetime.date(2022, 11, 11),\n",
    "     datetime.date(2022, 11, 12),\n",
    "     datetime.date(2022, 11, 22),\n",
    "     datetime.date(2022, 12, 25)]}\n",
    ")\n",
    "\n",
    "us_ca_holidays['holiday'] = pd.to_datetime(us_ca_holidays['holiday'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def nearest_holiday(date_series, holidays):\n",
    "#    min_holiday_dist = []\n",
    "#    for i, date in enumerate(date_series):\n",
    "#        min_holiday_dist.append(min(abs(holidays - date)).days)\n",
    "#    return(min_holiday_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = [date.date() for date in us_ca_holidays['holiday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = calendar.assign(holiday = [True if date.date() in holidays else False for date in calendar.date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_duration_agg = calendar.groupby('listing_id')[['available', 'minimum_nights', 'maximum_nights']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of week aggregations\n",
    "dow_agg = calendar.groupby(['listing_id', 'day_of_week'])[['price']].mean()\n",
    "dow_agg = dow_agg.reset_index()\n",
    "dow_pivot = dow_agg.pivot(index='listing_id', columns='day_of_week', values='price').reset_index()\n",
    "dow_columns = ['listing_id'] + ['day_of_week_' + str(i) for i in dow_pivot.columns[1:]]\n",
    "dow_pivot.columns = dow_columns\n",
    "\n",
    "# week of year aggregations\n",
    "woy_agg = calendar.groupby(['listing_id', 'week_of_year'])[['price']].mean()\n",
    "woy_agg = woy_agg.reset_index()\n",
    "woy_pivot = woy_agg.pivot(index='listing_id', columns='week_of_year', values='price').reset_index()\n",
    "woy_columns = ['listing_id'] + ['week_of_year_' + str(i) for i in woy_pivot.columns[1:]]\n",
    "woy_pivot.columns = woy_columns\n",
    "\n",
    "# day of week aggregations\n",
    "moy_agg = calendar.groupby(['listing_id', 'month_of_year'])[['price']].mean()\n",
    "moy_agg = moy_agg.reset_index()\n",
    "moy_pivot = moy_agg.pivot(index='listing_id', columns='month_of_year', values='price').reset_index()\n",
    "moy_columns = ['listing_id'] + ['month_of_year_' + str(i) for i in moy_pivot.columns[1:]]\n",
    "moy_pivot.columns = moy_columns\n",
    "\n",
    "# day of week aggregations\n",
    "year_agg = calendar.groupby(['listing_id', 'year'])[['price']].mean()\n",
    "year_agg = year_agg.reset_index()\n",
    "year_pivot = year_agg.pivot(index='listing_id', columns='year', values='price').reset_index()\n",
    "year_columns = ['listing_id'] + ['year_' + str(i) for i in year_pivot.columns[1:]]\n",
    "year_pivot.columns = year_columns\n",
    "\n",
    "# holiday aggregations\n",
    "holiday_agg = calendar.groupby(['listing_id', 'holiday'])[['price']].mean()\n",
    "holiday_agg = holiday_agg.reset_index()\n",
    "holiday_pivot = holiday_agg.pivot(index='listing_id', columns='holiday', values='price').reset_index()\n",
    "holiday_columns = ['listing_id'] + ['holiday_' + str(i) for i in holiday_pivot.columns[1:]]\n",
    "holiday_pivot.columns = holiday_columns\n",
    "\n",
    "# Merge together\n",
    "calendar_aggregates = dow_pivot.merge(woy_pivot, on='listing_id').merge(moy_pivot, on='listing_id').merge(year_pivot, on='listing_id').merge(holiday_pivot, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_aggregates = calendar_aggregates.merge(calendar_duration_agg, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_aggregates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-biography",
   "metadata": {},
   "source": [
    "## Listings Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_columns = ['id',\n",
    "                     'host_id',\n",
    "                     'host_response_time',\n",
    "                     'host_response_rate',\n",
    "                     'host_acceptance_rate',\n",
    "                     'host_is_superhost',\n",
    "                     'host_neighbourhood',\n",
    "                     'host_listings_count',\n",
    "                     'host_total_listings_count',\n",
    "                     'host_has_profile_pic',\n",
    "                     'host_identity_verified',\n",
    "                     'neighbourhood_cleansed',\n",
    "                     'neighbourhood_group_cleansed',\n",
    "                     'latitude',\n",
    "                     'longitude',\n",
    "                     'property_type',\n",
    "                     'room_type',\n",
    "                     'accommodates',\n",
    "                     'bedrooms',\n",
    "                     'beds',\n",
    "                     'price',\n",
    "                     'minimum_nights',\n",
    "                     'maximum_nights',\n",
    "                     'minimum_minimum_nights',\n",
    "                     'maximum_minimum_nights',\n",
    "                     'minimum_maximum_nights',\n",
    "                     'maximum_maximum_nights',\n",
    "                     'minimum_nights_avg_ntm',\n",
    "                     'maximum_nights_avg_ntm',\n",
    "                     'has_availability',\n",
    "                     'availability_30',\n",
    "                     'availability_60',\n",
    "                     'availability_90',\n",
    "                     'availability_365',\n",
    "                     'number_of_reviews',\n",
    "                     'number_of_reviews_ltm',\n",
    "                     'number_of_reviews_l30d',\n",
    "                     'review_scores_rating',\n",
    "                     'review_scores_accuracy',\n",
    "                     'review_scores_cleanliness',\n",
    "                     'review_scores_checkin',\n",
    "                     'review_scores_communication',\n",
    "                     'review_scores_location',\n",
    "                     'review_scores_value',\n",
    "                     'instant_bookable',\n",
    "                     'calculated_host_listings_count',\n",
    "                     'calculated_host_listings_count_entire_homes',\n",
    "                     'calculated_host_listings_count_private_rooms',\n",
    "                     'calculated_host_listings_count_shared_rooms',\n",
    "                     'reviews_per_month',\n",
    "                     'desc_apartment',\n",
    "                     'desc_located',\n",
    "                     'desc_space',\n",
    "                     'desc_home',\n",
    "                     'desc_bed',\n",
    "                     'desc_room',\n",
    "                     'desc_kitchen',\n",
    "                     'desc_access',\n",
    "                     'desc_one',\n",
    "                     'desc_private',\n",
    "                     'desc_san',\n",
    "                     'desc_francisco',\n",
    "                     'desc_bathroom',\n",
    "                     'desc_bedroom',\n",
    "                     'desc_living',\n",
    "                     'host_in_sf',\n",
    "                     'host_verifications_email',\n",
    "                     'host_verifications_facebook',\n",
    "                     'host_verifications_google',\n",
    "                     'host_verifications_government_id',\n",
    "                     'host_verifications_identity_manual',\n",
    "                     'host_verifications_jumio',\n",
    "                     'host_verifications_kba',\n",
    "                     'host_verifications_manual_offline',\n",
    "                     'host_verifications_manual_online',\n",
    "                     'host_verifications_offline_government_id',\n",
    "                     'host_verifications_phone',\n",
    "                     'host_verifications_reviews',\n",
    "                     'host_verifications_selfie',\n",
    "                     'host_verifications_sent_id',\n",
    "                     'host_verifications_work_email',\n",
    "                     'host_verifications_zhima_selfie',\n",
    "                     'bathroom_private',\n",
    "                     'bathroom_shared',\n",
    "                     'bathroom_half',\n",
    "                     'bathroom_count',\n",
    "                     'amenities_Wifi',\n",
    "                     'amenities_Smoke alarm',\n",
    "                     'amenities_Essentials',\n",
    "                     'amenities_Heating',\n",
    "                     'amenities_Hangers',\n",
    "                     'amenities_Carbon monoxide alarm',\n",
    "                     'amenities_Hair dryer',\n",
    "                     'amenities_Iron',\n",
    "                     'amenities_Long term stays allowed',\n",
    "                     'amenities_Kitchen',\n",
    "                     'amenities_Shampoo',\n",
    "                     'amenities_Dedicated workspace',\n",
    "                     'amenities_Hot water',\n",
    "                     'amenities_Washer',\n",
    "                     'amenities_Fire extinguisher',\n",
    "                     'amenities_Dryer',\n",
    "                     'amenities_Coffee maker',\n",
    "                     'amenities_Refrigerator',\n",
    "                     'amenities_Microwave',\n",
    "                     'amenities_Dishes and silverware',\n",
    "                     'amenities_Bed linens',\n",
    "                     'amenities_TV',\n",
    "                     'amenities_Cooking basics',\n",
    "                     'amenities_First aid kit',\n",
    "                     'amenities_Private entrance',\n",
    "                     'amenities_Free street parking',\n",
    "                     'amenities_Oven',\n",
    "                     'amenities_Stove',\n",
    "                     'amenities_Extra pillows and blankets',\n",
    "                     'amenities_Dishwasher',\n",
    "                     'review_span',\n",
    "                     't_since_last_review',\n",
    "                     't_as_host',\n",
    "                     'has_license']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the desired features\n",
    "listings_modeling = listings[modeling_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "listings_modeling.rename(columns={'id' : 'listing_id', 'price' : 'listing_price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_modeling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-grammar",
   "metadata": {},
   "source": [
    "## Create the Modeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = calendar[['listing_id', 'date', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.merge(agg_reviews, on='listing_id').merge(calendar_aggregates, on='listing_id').merge(listings_modeling, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-ending",
   "metadata": {},
   "source": [
    "## Split into Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create smaller dataset for testing code\n",
    "train_fraction = 0.8\n",
    "number_of_listings = len(set(base.listing_id))\n",
    "\n",
    "train_size = round(train_fraction * number_of_listings)\n",
    "train_ids = random.sample(list(set(base.listing_id)), train_size)\n",
    "test_ids = [listing for listing in base.listing_id if listing not in train_ids]\n",
    "\n",
    "train_data = base.query(\"listing_id in @train_ids\")\n",
    "test_data = base.query(\"listing_id in @test_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train_data.listing_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(test_data.listing_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output path\n",
    "out_path = \"../data/ready_for_modeling/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make processed folder\n",
    "#if ~os.direxists(\"../data/ready_for_modeling\"):\n",
    "#    os.mkdir(\"../data/ready_for_modeling\")\n",
    "try:\n",
    "    os.mkdir(\"../data/ready_for_modeling\")\n",
    "except:\n",
    "    print(\"Processed directory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disc\n",
    "train_path = out_path + \"training_data.csv\"\n",
    "train_data.to_csv(train_path)\n",
    "\n",
    "test_path = out_path + \"testing_data.csv\"\n",
    "test_data.to_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-portugal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
